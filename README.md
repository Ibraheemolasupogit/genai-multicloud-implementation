GenAI Multi-Cloud Implementation & Ops: Ollama • LangChain • Hugging Face • OpenAI • Gemini/Vertex • Azure AI • SageMaker
This repository showcases my end-to-end implementations and operational workflows for generative AI solutions across local, cloud, and hybrid environments.
It covers practical development, deployment, and integration of large language models (LLMs) and multimodal AI systems — spanning local inference (Ollama), vector-based retrieval (LangChain + Chroma), cloud-native model APIs (OpenAI, Gemini/Vertex AI, Azure OpenAI, AWS SageMaker), model hosting & collaboration (Hugging Face), and production orchestration (GenAI Ops).

Key focus:

Applying GenAI capabilities in real-world NHS and healthcare contexts, such as:

Summarising lengthy clinical guidelines for operational or frontline use.

Creating patient-friendly explanations from complex diagnostic reports.

Building RAG search tools for internal knowledge bases (e.g., NICE guidelines, COSD datasets).

Designing nutritional advice generators for oncology and diabetic patients.

Building multi-cloud workflows that are secure, reproducible, and optimised for sensitive data handling.

Demonstrating reusable patterns that work beyond healthcare — in operations, research, and general business intelligence.

