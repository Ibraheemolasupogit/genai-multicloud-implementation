{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1992bc8e-ac15-4fef-b6b6-be9ee051cac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ed0bf0-085d-441f-8f3d-8738edf534a2",
   "metadata": {},
   "source": [
    "# 1. Basic Single Chain\n",
    "LangChain is a powerful framework for developing applications that leverage large language models (LLMs)\n",
    "At its core is the Basic Single Chain (also called an LLMChain), which represents the simplest possible workflow: you provide a single prompt to an LLM, and the model returns a single response\n",
    "Despite its simplicity, the Basic Single Chain underpins more complex multi-step chains, making it a fundamental building block in LangChain’s ecosystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "545efae3-3cc5-4cc3-a610-c8bcaba4d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cf16f8f-a2fe-43f0-ab07-0a9e2915aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\n",
    "        \"What is the capital of {country}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d91014c5-508e-456f-8243-2a16a8f86321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='What is the capital of {country}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "chat_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d990465-235d-44ac-97b9-7b1a37276c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "522497a8-7c28-4d90-82d6-46914e933085",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_prompt_template | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20061dea-52b8-4f5f-b5b7-d7d296fad32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='What is the capital of {country}'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000013299C14D90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000013299E88880>, root_client=<openai.OpenAI object at 0x0000013296677A90>, root_async_client=<openai.AsyncOpenAI object at 0x0000013299C14E80>, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "903ad307-1141-4166-bdea-98d3666ba57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke(input = \"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed71d5a5-d974-46c0-a2b0-15eb1a2b4fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is New Delhi.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e548317-a6a2-4157-9af0-e016ce0057d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d5d7d6b-f2d0-42b6-9a59-1448bc3615d7",
   "metadata": {},
   "source": [
    "# 2. Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "882f2089-d9fe-4ec4-9115-db8862b0439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f4529ea-b90a-4255-ba1d-5032c00b0025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3cce8a4-5cd6-4620-ac67-35896fd7718d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit\\AppData\\Local\\Temp\\ipykernel_6116\\1506918662.py:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI()\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea37f0bb-0266-40f9-accf-638579143a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template_1\n",
    "prompt_template_1 = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"What is the capital of {country}.\"\n",
    ")\n",
    "\n",
    "# prompt_template_2\n",
    "prompt_template_2 = PromptTemplate(\n",
    "    input_variables=[\"paragraph\"],\n",
    "    template=\"reverse the string:\\n\\n{paragraph}\"\n",
    ")\n",
    "\n",
    "# prompt_template_3\n",
    "prompt_template_3 = PromptTemplate(\n",
    "    input_variables=[\"my_str\"],\n",
    "    template=\"capitalise all the letters:\\n\\n{my_str}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e45c423-342e-4932-abe9-747c87d268ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit\\AppData\\Local\\Temp\\ipykernel_6116\\1193474285.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain_1 = LLMChain(llm=llm, prompt=prompt_template_1)\n"
     ]
    }
   ],
   "source": [
    "chain_1 = LLMChain(llm=llm, prompt=prompt_template_1)\n",
    "chain_2 = LLMChain(llm=llm, prompt=prompt_template_2)\n",
    "chain_3 = LLMChain(llm=llm, prompt=prompt_template_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5883d717-4bb5-487f-9ee9-b037d46c2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_chain = SimpleSequentialChain(chains=[chain_1, chain_2, chain_3], \n",
    "                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df232c27-8c8c-40f9-93e9-dcb8f1fa712f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "The capital of USA is Washington, D.C.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "C.D. ,notgnihsaW si ASU of latipaC ehT\u001b[0m\n",
      "\u001b[38;5;200m\u001b[1;3m\n",
      "\n",
      "\n",
      "C.D. ,NOTGNIHSAW SI ASU OF LATIPAC EHT\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = seq_chain.run(\"USA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f59700-8d57-48f9-a30a-05a2560bb71b",
   "metadata": {},
   "source": [
    "# 3. Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd24e7e2-6a9f-4e91-8f8c-c248f9e2ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains.sequential import SequentialChain\n",
    "\n",
    "# 1. Initialize the OpenAI Chat LLM\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fedd0e8-acf1-4eb8-994e-9c4996c7687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template1 = \"Summarize the key points of this product review:{review}\"\n",
    "prompt1 = ChatPromptTemplate.from_template(template1)\n",
    "chain_1 = prompt1 | llm\n",
    "\n",
    "template2 = \"From the summary, identify the top 3 issues or complaints the user has with the product: {review_summary}\"\n",
    "prompt2 = ChatPromptTemplate.from_template(template2)\n",
    "chain_2 = prompt2 | llm\n",
    "\n",
    "template3 = \"Propose an improvement plan to address these 3 main issues, aiming to enhance the product experience for future customers:{issues}\"\n",
    "prompt3 = ChatPromptTemplate.from_template(template3)\n",
    "chain_3 = prompt3 | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44fd1778-ccf2-4f58-8f03-2dde68fedcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_chain = chain_1 | chain_2 | chain_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abcea851-b888-4985-8198-705d782a0c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_review = \"\"\"\n",
    "Product Name: SuperSonic Blender\n",
    "\n",
    "Review Details:\n",
    "I purchased the SuperSonic Blender 3 weeks ago, and overall, I am quite disappointed. \n",
    "While the blender does look sleek, I noticed a burning smell coming from the motor \n",
    "after about a week of light use. It still blends, but I worry it's a sign of low-quality \n",
    "parts. Additionally, I find it very noisy compared to other blenders I've owned in \n",
    "the past – enough to wake my entire household if I use it in the morning. \n",
    "\n",
    "Another concern is the blend consistency. Despite the powerful-sounding motor, \n",
    "it sometimes leaves large chunks of fruit unprocessed, so I have to re-blend or stir \n",
    "manually. Lastly, the instruction manual is not very user-friendly. The diagrams \n",
    "are confusing, and there are no clear cleaning instructions besides a single-line note \n",
    "saying 'wash thoroughly.' For the price I paid, I expected much better performance \n",
    "and clarity.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3858b032-8b87-4adf-844b-baaace1a0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = seq_chain.invoke(product_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89bcdd9e-2be7-4b39-8415-8199542a9886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement Plan:\n",
      "\n",
      "1. Address the burning smell from the motor after light use by conducting a thorough inspection of the motor and its components. Identify any potential issues such as overheating or friction that may be causing the smell. Implement regular maintenance checks to ensure that the motor is running smoothly and efficiently.\n",
      "\n",
      "2. Reduce the noisy operation of the product by incorporating sound-dampening materials or improving the design of the product to minimize noise levels. Conduct a sound analysis to identify the source of the noise and implement measures to reduce it. This could involve using quieter motor components or adding insulation to the product.\n",
      "\n",
      "3. Improve blend consistency by optimizing the blending process and ensuring that all fruits are processed evenly. This could involve adjusting the speed or blending time to ensure that all ingredients are properly mixed. Conduct regular quality control checks to monitor blend consistency and make necessary adjustments to the blending process.\n",
      "\n",
      "Overall, by addressing these issues and implementing these improvements, we aim to enhance the product experience for future customers, providing a more reliable and efficient blending solution.\n"
     ]
    }
   ],
   "source": [
    "print(results.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9987aac4-97f8-4946-83db-4b218c41ad17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SuperSonic Blender has a sleek design but lacks quality as the motor emits a burning smell after light use. It is also very noisy and leaves chunks of fruit unprocessed despite its powerful motor. The instruction manual is confusing and lacks clear cleaning instructions. Overall, the reviewer is disappointed with the performance and expected better for the price paid.\n"
     ]
    }
   ],
   "source": [
    "print(chain_1.invoke(product_review).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d122063-4832-482e-ba2b-06857d38e357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Burning smell coming from the motor after light use\n",
      "2. Noisy operation\n",
      "3. Inconsistent blending, leaving chunks of fruit unprocessed\n"
     ]
    }
   ],
   "source": [
    "print((chain_1|chain_2).invoke(product_review).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acb4a663-a7c3-4ab3-a7ec-bb9e55db2b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To address the issues with the blender, here is an improvement plan:\n",
      "\n",
      "1. Burning smell from the motor: \n",
      "   - Conduct a thorough inspection of the motor to identify the root cause of the burning smell.\n",
      "   - Implement proper ventilation to prevent overheating.\n",
      "   - Regularly clean the motor to avoid dust accumulation, which can lead to overheating.\n",
      "\n",
      "2. Noisy operation: \n",
      "   - Inspect the blades and jar to ensure they are properly aligned and secure.\n",
      "   - Use soundproofing materials to reduce the noise level during operation.\n",
      "   - Consider replacing the motor if it is the primary source of the noise.\n",
      "\n",
      "3. Inconsistent blend consistency:\n",
      "   - Check the blade assembly for any damages or misalignments that could be causing the chunks of fruit to remain unprocessed.\n",
      "   - Adjust the blending speed and duration to ensure a more consistent blend.\n",
      "   - Provide clear instructions to customers on how to achieve the desired blend consistency.\n",
      "\n",
      "By implementing these improvements, we aim to enhance the overall product experience for future customers by addressing the main issues reported and ensuring a more reliable and efficient blender performance.\n"
     ]
    }
   ],
   "source": [
    "print((chain_1|chain_2|chain_3).invoke(product_review).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb86dbea-3990-470e-bf4c-213538823973",
   "metadata": {},
   "source": [
    "# 4. LLMRouterChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb3731b8-fa9c-467b-a683-d217ebbfffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "988fbbb5-3ebc-4703-8a49-da0e93f06c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_template = \"empty\"\n",
    "\n",
    "physics_template = \"\"\"You are a physics professor with advanced knowledge of \n",
    "classical mechanics, electromagnetism, and quantum theory. Provide \n",
    "in-depth explanations with real-world analogies. Here is the question:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "chemistry_template = \"\"\"You are a chemistry professor with deep expertise in \n",
    "organic and physical chemistry. Provide a thorough explanation with \n",
    "relevant examples. Here is the question:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "math_template = \"\"\"You are a mathematics professor with a strong background in \n",
    "algebra, calculus, and number theory. Provide step-by-step solutions.\n",
    "Here is the question:\n",
    "{input}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5225c60-647d-4554-b949-b5467fa6f77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"empty\",\n",
    "        \"description\": \"Replies to empty questions\",\n",
    "        \"prompt_template\": empty_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"physics\",\n",
    "        \"description\": \"Answers physics questions\",\n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"chemistry\",\n",
    "        \"description\": \"Answers chemistry questions\",\n",
    "        \"prompt_template\": chemistry_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\",\n",
    "        \"description\": \"Answers math questions\",\n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "199777be-c81e-4889-9bc3-917507a23238",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d9390a0-21db-4213-9500-076aaade33cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit\\miniconda3\\envs\\genai_env\\lib\\site-packages\\pydantic\\main.py:212: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    }
   ],
   "source": [
    "chain = MultiPromptChain.from_prompts(llm, prompt_infos, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7fe260f-ad99-4e01-bc3b-9baab1c358e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is the difference between potential and kinetic energy?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Physics Answer ---\n",
      "{'input': 'What is the difference between potential and kinetic energy?', 'text': \"Potential energy and kinetic energy are both forms of energy that an object possesses, but they represent different aspects of the object's motion and position in a physical system.\\n\\nLet's start with potential energy. Potential energy is the energy that an object possesses due to its position or configuration relative to another object. It is essentially stored energy that has the potential to do work. Think of a roller coaster at the top of a hill - when the roller coaster car is at the top of the hill, it has a high potential energy because it is elevated above the ground and has the potential to create movement as it accelerates down the hill. Another common example is a spring that is compressed - the spring has potential energy stored in it due to its compressed state, and when released, this potential energy is converted into kinetic energy as the spring expands.\\n\\nOn the other hand, kinetic energy is the energy that an object possesses due to its motion. It is the energy of motion, and it depends on both the object's mass and its velocity. Going back to the roller coaster example, as the car accelerates down the hill, its potential energy is converted into kinetic energy - the faster it goes, the more kinetic energy it possesses. Similarly, the faster a moving car is traveling, the more kinetic energy it has due to its increased velocity.\\n\\nIn summary, potential energy is the energy of position or configuration, while kinetic energy is the energy of motion. The relationship between the two can be seen in many everyday situations, such as a pendulum swinging back and forth (where potential energy is constantly being converted into kinetic energy and vice versa), or a bow and arrow being pulled back before releasing (potential energy stored in the stretched bowstring is converted into kinetic energy as the arrow is released).\"}\n"
     ]
    }
   ],
   "source": [
    "physics_question = \"What's the difference between potential and kinetic energy?\"\n",
    "physics_response = chain.invoke(physics_question)\n",
    "print(\"\\n--- Physics Answer ---\")\n",
    "print(physics_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09469195-62cf-4e1e-a368-214d349a997d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "chemistry: {'input': 'How do you balance a redox reaction in a chemistry problem?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Chemistry Answer ---\n",
      "{'input': 'How do you balance a redox reaction in a chemistry problem?', 'text': 'Balancing a redox reaction involves ensuring that the number of electrons lost in the oxidation half-reaction is equal to the number of electrons gained in the reduction half-reaction. To balance a redox reaction, you can follow these general steps:\\n\\n1. Write the unbalanced chemical equation for the redox reaction, showing the oxidation and reduction half-reactions separately.\\n\\n2. Identify the oxidation numbers for each element in the reaction. This will help you determine which elements are undergoing oxidation and reduction.\\n\\n3. Balance the elements in each half-reaction, except for oxygen and hydrogen atoms, by adding appropriate coefficients in front of the chemical species involved.\\n\\n4. Balance the oxygen atoms by adding water molecules (H2O) to the side lacking oxygen atoms.\\n\\n5. Balance the hydrogen atoms by adding hydrogen ions (H+) to the side lacking hydrogen atoms.\\n\\n6. Balance the charge by adding electrons to one side of the reaction to equalize the total charge on both sides. Electrons are added to the side with the higher positive charge.\\n\\n7. Multiply each half-reaction by an appropriate factor to ensure that the number of electrons lost in the oxidation half-reaction equals the number of electrons gained in the reduction half-reaction. This step may involve adding another molecule or ion to balance the number of electrons.\\n\\n8. Add the balanced half-reactions together to obtain the overall balanced redox reaction.\\n\\nFor example, consider the redox reaction between potassium dichromate (K2Cr2O7) and sulfur dioxide (SO2) in acidic solution:\\n\\nK2Cr2O7 + SO2 + H2O -> K2SO4 + Cr2(SO4)3 + H2SO4\\n\\n1. Determine the oxidation states: \\n\\nK2Cr2O7: K(+1), Cr(+6), O(-2)\\nSO2: S(+4), O(-2)\\n\\n2. Write the half-reactions:\\n\\nOxidation (loss of electrons): Cr2O7^2- -> Cr3+\\nReduction (gain of electrons): SO2 -> SO4^2-\\n\\n3. Balance the half-reactions:\\n\\nOxidation: Cr2O7^2- -> 2Cr3+\\nReduction: SO2 -> SO4^2-\\n\\n4. Balance the oxygen atoms with water and hydrogen atoms with H+ ions:\\n\\nCr2O7^2- -> 2Cr3+ + 7H2O\\nSO2 + 2H2O -> SO4^2- + 4H+\\n\\n5. Balance the charges with electrons:\\n\\nCr2O7^2- + 14H+ -> 2Cr3+ + 7H2O + 6e-\\nSO2 + 2H2O -> SO4^2- + 4H+ + 2e-\\n\\n6. Multiply the half-reactions to balance the number of electrons:\\n\\n2(Cr2O7^2- + 14H+ -> 2Cr3+ + 7H2O + 6e-)\\n3(SO2 + 2H2O -> SO4^2- + 4H+ + 2e-)\\n\\nAdding the balanced half-reactions yields the overall balanced redox reaction:\\n\\n2K2Cr2O7 + 3SO2 + 8H2O -> 2K2SO4 + 3Cr2(SO4)3 + 3H2SO4\\n\\nBy following these steps, you can effectively balance redox reactions in chemistry problems.'}\n"
     ]
    }
   ],
   "source": [
    "chemistry_question = \"How do you balance a redox reaction?\"\n",
    "chemistry_response = chain.invoke(chemistry_question)\n",
    "print(\"\\n--- Chemistry Answer ---\")\n",
    "print(chemistry_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef5a723d-0baa-47e3-92e8-e4d530f1b77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'What is the derivative of sin(x)?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Math Answer ---\n",
      "{'input': 'What is the derivative of sin(x)?', 'text': \"The derivative of sin(x) is cos(x).\\n\\nTo prove this, we can use the definition of the derivative:\\n\\nf'(x) = lim(h -> 0) [f(x + h) - f(x)] / h\\n\\nIn this case, f(x) = sin(x), so we have:\\n\\nsin'(x) = lim(h -> 0) [sin(x + h) - sin(x)] / h\\n\\nUsing the angle addition formula for sine, sin(a + b) = sin(a)cos(b) + cos(a)sin(b), we have:\\n\\nsin(x + h) = sin(x)cos(h) + cos(x)sin(h)\\n\\nSubstitute this expression into the derivative formula:\\n\\nsin'(x) = lim(h -> 0) [(sin(x)cos(h) + cos(x)sin(h)) - sin(x)] / h\\n\\n= lim(h -> 0) [sin(x)cos(h) + cos(x)sin(h) - sin(x)] / h\\n\\n= lim(h -> 0) [sin(x)(cos(h) - 1) + cos(x)sin(h)] / h\\n\\n= sin(x) * lim(h -> 0) [(cos(h) - 1) / h] + cos(x) * lim(h -> 0) [sin(h) / h]\\n\\nNow, as h approaches 0, the limits become the derivatives of cosine and sine:\\n\\n= sin(x) * (d/dh cos(h) at h=0) + cos(x) * (d/dh sin(h) at h=0)\\n\\n= sin(x) * (-sin(0)) + cos(x) * cos(0)\\n\\n= sin(x) * 0 + cos(x) * 1\\n\\n= cos(x)\\n\\nTherefore, the derivative of sin(x) is cos(x).\"}\n"
     ]
    }
   ],
   "source": [
    "math_question = \"What is the derivative of sin(x)?\"\n",
    "math_response = chain.invoke(math_question)\n",
    "print(\"\\n--- Math Answer ---\")\n",
    "print(math_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ec95c4b-2e45-4611-818e-70e4e961e206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'There is no input provided.'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Empty Question Answer ---\n",
      "{'input': 'There is no input provided.', 'history': '', 'text': 'Hello! How can I assist you today?'}\n"
     ]
    }
   ],
   "source": [
    "empty_question = \"\"\n",
    "empty_response = chain.invoke(empty_question)\n",
    "print(\"\\n--- Empty Question Answer ---\")\n",
    "print(empty_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9cd894-a3ee-4c22-9389-e8f18ff4eba8",
   "metadata": {},
   "source": [
    "# 5. TransformChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70eb04f6-9e7b-41a1-95d0-44f987c8ca52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Review Text:\n",
      "\n",
      "REVIEW: This place was amazing! The food was great, though it was a bit pricey.\n",
      "Service was fast, but the waiter seemed rushed. Overall, I really liked it!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import TransformChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "yelp_review = \"\"\"\n",
    "REVIEW: This place was amazing! The food was great, though it was a bit pricey.\n",
    "Service was fast, but the waiter seemed rushed. Overall, I really liked it!\n",
    "\"\"\"\n",
    "\n",
    "print(\"Original Review Text:\")\n",
    "print(yelp_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d94b800c-5271-46c7-bc38-38cf64ec8ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_fun(inputs: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Takes an input dictionary with the key 'text', removes punctuation,\n",
    "    and returns a new dictionary containing the cleaned text.\n",
    "    \"\"\"\n",
    "    import string\n",
    "    \n",
    "    text = inputs['text']\n",
    "    \n",
    "    # Extract everything after \"REVIEW:\" (similar to the original example)\n",
    "    only_review_text = text.split('REVIEW:')[-1].strip()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    cleaned_text = only_review_text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Return the cleaned text in a dictionary\n",
    "    return {'cleaned_text': cleaned_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec629237-5596-481d-8273-d5c31a77bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_chain = TransformChain(\n",
    "    input_variables=['text'],\n",
    "    output_variables=['cleaned_text'],\n",
    "    transform=transformer_fun\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1651d4be-1d22-42d0-842e-9bdf09efac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_result = transform_chain.invoke(yelp_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17128b79-22b3-454c-bacf-73516703b815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '\\nREVIEW: This place was amazing! The food was great, though it was a bit pricey.\\nService was fast, but the waiter seemed rushed. Overall, I really liked it!\\n',\n",
       " 'cleaned_text': 'This place was amazing The food was great though it was a bit pricey\\nService was fast but the waiter seemed rushed Overall I really liked it'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f3f60c0-9796-4946-a636-c3e1eac61f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Analyze the following restaurant review and list the main pros and cons in bullet points:\n",
    "{cleaned_text}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "395bd912-050b-4c2f-bdcd-9cd1c7a50638",
   "metadata": {},
   "outputs": [],
   "source": [
    "pros_cons_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c788fc70-190e-4026-b406-47f2dfed57b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_chain = transform_chain | pros_cons_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a0dde31-c85b-44a9-8b7b-2a6368a99872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pros & Cons Analysis ---\n",
      "Pros:\n",
      "- Amazing place\n",
      "- Great food\n",
      "- Fast service\n",
      "\n",
      "Cons:\n",
      "- Pricey\n",
      "- Waiter seemed rushed\n"
     ]
    }
   ],
   "source": [
    "result = sequential_chain.invoke(yelp_review)\n",
    "\n",
    "print(\"\\n--- Pros & Cons Analysis ---\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90431193-d45a-47c6-b619-502f896e6854",
   "metadata": {},
   "source": [
    "# 6. Using OpenAI Functions API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "39e32ea4-a13a-48bb-a3aa-e2089f81dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain.chains.openai_functions import (\n",
    "    create_openai_fn_chain,\n",
    "    create_structured_output_chain,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "# Initialize the OpenAI Chat LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ed13a82e-c610-4e71-9dd9-f1cbd0eb9003",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = {\n",
    "    \"title\": \"MathematicianInfo\",\n",
    "    \"description\": \"Information about a famous mathematician with birth year and a major theorem or discovery\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"first_name\": {\n",
    "            \"title\": \"First Name\",\n",
    "            \"description\": \"The first name of the mathematician\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        \"last_name\": {\n",
    "            \"title\": \"Last Name\",\n",
    "            \"description\": \"The last name of the mathematician\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        \"birth_year\": {\n",
    "            \"title\": \"Birth Year\",\n",
    "            \"description\": \"The year the mathematician was born\",\n",
    "            \"type\": \"integer\"\n",
    "        },\n",
    "        \"major_theorem\": {\n",
    "            \"title\": \"Major Theorem or Discovery\",\n",
    "            \"description\": \"A significant theorem or discovery by this mathematician\",\n",
    "            \"type\": \"string\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"first_name\", \"last_name\", \"birth_year\", \"major_theorem\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed44c43d-c395-483e-888d-b1c2de8eca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = (\n",
    "    \"Name a famous {country} mathematician whose primary field of research is {study}, \"\n",
    "    \"mention the mathematician's birth year, and describe one of their notable theorems or discoveries.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2da9ad81-fcd4-4e9c-8e65-a77d6910292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1e781a18-b6b3-493a-85e8-a03fe32ea59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['country', 'study'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['country', 'study'], input_types={}, partial_variables={}, template=\"Name a famous {country} mathematician whose primary field of research is {study}, mention the mathematician's birth year, and describe one of their notable theorems or discoveries.\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "95370cf2-57fd-49ff-a6d9-7e620c6273f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_prompt | llm.with_structured_output(schema=json_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5f95bb9b-0dbd-4f8b-870f-bf6260338e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\n",
    "    \"country\" : \"Indian\",\n",
    "    \"study\" : \"Algebra\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7aca5117-75c1-4aea-b127-4bbdb3a2192b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_name': 'Bhargav',\n",
       " 'last_name': 'Bhatt',\n",
       " 'birth_year': 1983,\n",
       " 'major_theorem': \"Developed important concepts and advances in 'p-adic geometry' and its applications to algebraic geometry. His work on the theory of derived algebraic geometry and the development of 'mod p' and 'p-adic cohomologies' has significantly influenced modern algebraic techniques.\"}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4340eae3-dd28-4d3d-bf3a-a6247c72d255",
   "metadata": {},
   "source": [
    "# 7. MathChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7079e040-b5ae-452a-9b86-b5b6d16cf4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a6b48c07-c33b-4b21-84c8-6c0b4df4a223",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.invoke([HumanMessage(content=\"Multiply 23456789 by 87567646\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "091e9740-ade2-4479-baa3-a58f7c57597f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='2051291481711994', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 17, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-65c537ce-5977-4416-809e-ae198f9d9c2e-0', usage_metadata={'input_tokens': 17, 'output_tokens': 7, 'total_tokens': 24, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ba376d31-ab29-44ef-8609-2cfa1925e87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2054055795448694"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(\"23456789 * 87567646\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b21addd9-aaf5-4caa-ae9f-2024032c61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMMathChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "92df22ae-110c-4610-83e7-15e840e828ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numexpr\n",
      "  Downloading numexpr-2.10.2-cp39-cp39-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\ankit\\miniconda3\\envs\\genai_env\\lib\\site-packages (from numexpr) (1.26.4)\n",
      "Downloading numexpr-2.10.2-cp39-cp39-win_amd64.whl (144 kB)\n",
      "Installing collected packages: numexpr\n",
      "Successfully installed numexpr-2.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bbcb15c9-add4-4040-a808-6cc7568016f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_math_model = LLMMathChain.from_llm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "74bcaa19-83e7-4726-9ea1-4163001e0003",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm_math_model.invoke(\"Multiply 23456789 by 87567646\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2026ffda-ccbb-446d-b092-e55df87a2c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Multiply 23456789 by 87567646',\n",
       " 'answer': 'Answer: 2054055795448694'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "83107bc2-c62f-40fa-bf4b-41c717d5811b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2054055795448694"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(\"23456789 * 87567646\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722bb9c2-e28e-4f9b-ad6b-60c5196aa951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
