{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e97e104-2ca5-48f3-bfb4-16f5a5afa7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables and setup\n",
    "load_dotenv()\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b90d8871-4de6-4137-9457-046749b51022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_webpage_summary(url):\n",
    "    \"\"\"\n",
    "    Extract text from URL and generate a summary using OpenAI API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch and parse webpage content\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        text = \" \".join([p.get_text() for p in soup.find_all(\"p\")])\n",
    "        \n",
    "        # Split text into chunks of approximately 4000 characters\n",
    "        chunks = [text[i:i + 4000] for i in range(0, len(text), 4000)]\n",
    "        \n",
    "        # Summarization prompt\n",
    "        summarization_prompt = \"\"\"\n",
    "        Please provide a concise summary of the following text. The summary should:\n",
    "        - Capture the main ideas and key points\n",
    "        - Be well-organized and coherent\n",
    "        - Maintain the original meaning and context\n",
    "        - Exclude any redundant or unnecessary information\n",
    "        \n",
    "        Text to summarize:\n",
    "        \"\"\"\n",
    "        \n",
    "        # Process chunks and get summaries\n",
    "        summaries = []\n",
    "        for i, chunk in enumerate(chunks, 1):\n",
    "            print(f\"Processing part {i} of {len(chunks)}...\")\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a precise and concise text summarizer.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"{summarization_prompt}\\n{chunk}\"}\n",
    "                ],\n",
    "                max_tokens=300,\n",
    "                temperature=0.5\n",
    "            )\n",
    "            summaries.append(response.choices[0].message.content.strip())\n",
    "        \n",
    "        # Combine summaries if needed\n",
    "        final_summary = \"\\n\\n\".join(summaries)\n",
    "        if len(chunks) > 1:\n",
    "            # Create a final, consolidated summary\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a precise and concise text summarizer.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Please consolidate these summaries into a single coherent summary:\\n{final_summary}\"}\n",
    "                ],\n",
    "                max_tokens=300,\n",
    "                temperature=0.5\n",
    "            )\n",
    "            final_summary = response.choices[0].message.content.strip()\n",
    "            \n",
    "        return final_summary\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06791d27-9cb4-4461-a102-557fb4a0ab8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the URL to summarize:  https://en.wikipedia.org/wiki/ChatGPT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing webpage...\n",
      "Processing part 1 of 13...\n",
      "Processing part 2 of 13...\n",
      "Processing part 3 of 13...\n",
      "Processing part 4 of 13...\n",
      "Processing part 5 of 13...\n",
      "Processing part 6 of 13...\n",
      "Processing part 7 of 13...\n",
      "Processing part 8 of 13...\n",
      "Processing part 9 of 13...\n",
      "Processing part 10 of 13...\n",
      "Processing part 11 of 13...\n",
      "Processing part 12 of 13...\n",
      "Processing part 13 of 13...\n",
      "\n",
      "--- Summary ---\n",
      "\n",
      "ChatGPT, an AI chatbot developed by OpenAI based on the GPT-4o model, has gained over 100 million users by January 2023, contributing to OpenAI's valuation of $86 billion. It uses supervised and reinforcement learning and has partnerships with companies like Microsoft and Apple. While versatile in tasks like writing, music composition, and idea generation, ChatGPT may produce incorrect responses and exhibit algorithmic bias. It faced criticisms for generating misinformation and has been banned on some platforms. OpenAI introduced premium services like ChatGPT Plus and API access for premium users. Despite concerns about inaccuracies and biases, ChatGPT has made significant advancements and collaborations, impacting various industries. Researchers have evaluated its applications in healthcare and legal contexts, noting its proficiency in medical education but also its limitations in accuracy and completeness. Legal and ethical issues, including copyright infringement and societal impacts, have been raised, emphasizing the importance of regulating AI development and addressing existential risks.\n"
     ]
    }
   ],
   "source": [
    "input_url = input(\"Enter the URL to summarize: \")\n",
    "print(\"Processing webpage...\")\n",
    "summary = get_webpage_summary(input_url)\n",
    "print(\"\\n--- Summary ---\\n\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dc2c23-7e2a-4d90-9032-0a83f449fab0",
   "metadata": {},
   "source": [
    "# Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38dae8f5-d14e-4566-ae0e-595bb41fa7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://c09b0bfa1a092ff233.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c09b0bfa1a092ff233.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing webpage...\n",
      "Processing part 1 of 4...\n",
      "Processing part 2 of 4...\n",
      "Processing part 3 of 4...\n",
      "Processing part 4 of 4...\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "\n",
    "# Load environment variables and setup\n",
    "load_dotenv()\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def get_webpage_summary(url):\n",
    "    \"\"\"\n",
    "    Extract text from URL and generate a summary using OpenAI API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch and parse webpage content\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        text = \" \".join([p.get_text() for p in soup.find_all(\"p\")])\n",
    "        \n",
    "        # Split text into chunks of approximately 4000 characters\n",
    "        chunks = [text[i:i + 4000] for i in range(0, len(text), 4000)]\n",
    "        \n",
    "        # Summarization prompt\n",
    "        summarization_prompt = \"\"\"\n",
    "        Please provide a concise summary of the following text. The summary should:\n",
    "        - Capture the main ideas and key points\n",
    "        - Be well-organized and coherent\n",
    "        - Maintain the original meaning and context\n",
    "        - Exclude any redundant or unnecessary information\n",
    "        \n",
    "        Text to summarize:\n",
    "        \"\"\"\n",
    "        \n",
    "        # Process chunks and get summaries\n",
    "        summaries = []\n",
    "        for i, chunk in enumerate(chunks, 1):\n",
    "            print(f\"Processing part {i} of {len(chunks)}...\")\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a precise and concise text summarizer.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"{summarization_prompt}\\n{chunk}\"}\n",
    "                ],\n",
    "                max_tokens=300,\n",
    "                temperature=0.5\n",
    "            )\n",
    "            summaries.append(response.choices[0].message.content.strip())\n",
    "        \n",
    "        # Combine summaries if needed\n",
    "        final_summary = \"\\n\\n\".join(summaries)\n",
    "        if len(chunks) > 1:\n",
    "            # Create a final, consolidated summary\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a precise and concise text summarizer.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Please consolidate these summaries into a single coherent summary:\\n{final_summary}\"}\n",
    "                ],\n",
    "                max_tokens=300,\n",
    "                temperature=0.5\n",
    "            )\n",
    "            final_summary = response.choices[0].message.content.strip()\n",
    "            \n",
    "        return final_summary\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "def gradio_interface(url):\n",
    "    \"\"\"\n",
    "    Wrapper function for Gradio interface\n",
    "    \"\"\"\n",
    "    if not url:\n",
    "        return \"Please enter a URL\"\n",
    "    \n",
    "    print(\"Processing webpage...\")\n",
    "    return get_webpage_summary(url)\n",
    "\n",
    "# Create Gradio interface\n",
    "demo = gr.Interface(\n",
    "    fn=gradio_interface,\n",
    "    inputs=gr.Textbox(label=\"Enter URL\", placeholder=\"https://example.com\"),\n",
    "    outputs=gr.Textbox(label=\"Summary\", lines=10),\n",
    "    title=\"Webpage Summarizer\",\n",
    "    description=\"Enter a URL to get a concise summary of the webpage content.\",\n",
    "    examples=[\n",
    "        [\"https://en.wikipedia.org/wiki/Artificial_intelligence\"],\n",
    "        [\"https://www.bbc.com/news\"],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d297f7-22c4-4f1a-bd91-5272c965362b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
